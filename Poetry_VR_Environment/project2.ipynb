{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 2 is created to find out whether a different approach in data cleaning works better for the chosen ML algorithm, XGBoost. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: \n",
    "1. Download data set\n",
    "2. Make ID column the name of the rows\n",
    "3. Delete columns with NaN data present\n",
    "4. Apply Ordinal Encoding to deal with categorical data\n",
    "5. Apply log transformation to turn the data into normal distribution\n",
    "6. Calculate MI scores\n",
    "7. Create new features\n",
    "8. Split the data into training and validation sets\n",
    "9. Apply scaling\n",
    "10. Apply XGBoost algorithm\n",
    "11. Apply GridSearch algorithm to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_set = \"/Users/serraus/Desktop/house-prices-advanced-regression-techniques/train.csv\"\n",
    "training_data = pd.read_csv(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.set_index(\"Id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_sheet import delete_columns\n",
    "delete_columns(training_data)\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_sheet import ordinal_encoder\n",
    "encoded_training_data = ordinal_encoder(training_data)\n",
    "print(encoded_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_transformation = np.log(encoded_training_data + 1)  # Adding 1 to handle zero values\n",
    "\n",
    "log_transformed_training_data = pd.DataFrame(log_transformation, columns=encoded_training_data.columns)\n",
    "print(log_transformed_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice       5.622458\n",
       "OverallQual     0.576310\n",
       "Neighborhood    0.505299\n",
       "GrLivArea       0.479071\n",
       "GarageCars      0.358855\n",
       "YearBuilt       0.353298\n",
       "TotalBsmtSF     0.344677\n",
       "GarageArea      0.337358\n",
       "KitchenQual     0.329060\n",
       "ExterQual       0.328872\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from function_sheet import mi_scores\n",
    "x = log_transformed_training_data\n",
    "y = log_transformed_training_data[\"SalePrice\"]\n",
    "mi = mi_scores(x, y)\n",
    "mi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AgeHouse    TotalSF  HasPool\n",
      "Id                                \n",
      "1     0.002492  20.257977        0\n",
      "2     0.015559  14.282490        0\n",
      "3     0.003490  20.415959        0\n",
      "4     0.046401  20.127741        0\n",
      "5     0.003990  21.048414        0\n",
      "...        ...        ...      ...\n",
      "1456  0.003992  20.265239        0\n",
      "1457  0.016040  14.978718        0\n",
      "1458  0.034914  21.181113        0\n",
      "1459  0.030290  13.967580        0\n",
      "1460  0.021636  14.272966        0\n",
      "\n",
      "[1460 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from function_sheet import new_features\n",
    "new_training_data_features = new_features(log_transformed_training_data)\n",
    "print(new_training_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice       5.618177\n",
       "TotalSF         0.704661\n",
       "OverallQual     0.563357\n",
       "Neighborhood    0.511352\n",
       "GrLivArea       0.478291\n",
       "GarageCars      0.369781\n",
       "YearBuilt       0.361298\n",
       "TotalBsmtSF     0.344872\n",
       "GarageArea      0.336872\n",
       "ExterQual       0.332089\n",
       "KitchenQual     0.329450\n",
       "AgeHouse        0.328601\n",
       "1stFlrSF        0.302648\n",
       "MSSubClass      0.273891\n",
       "FullBath        0.270397\n",
       "YearRemodAdd    0.237403\n",
       "TotRmsAbvGrd    0.214365\n",
       "2ndFlrSF        0.203994\n",
       "LotArea         0.199820\n",
       "Foundation      0.192036\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mi = mi_scores(x, y)\n",
    "new_mi.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LandSlope     0.003887\n",
       "RoofMatl      0.003290\n",
       "3SsnPorch     0.002357\n",
       "YrSold        0.002045\n",
       "Utilities     0.001026\n",
       "HasPool       0.000379\n",
       "PoolArea      0.000000\n",
       "MoSold        0.000000\n",
       "Condition2    0.000000\n",
       "Street        0.000000\n",
       "Functional    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mi.tail(11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low scored ones not removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = encoded_training_data.drop(\"SalePrice\", axis = 1)\n",
    "y_2 = encoded_training_data.SalePrice\n",
    "print(X_2, y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train/validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_2, x_valid_2, y_train_2, y_valid_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42) \n",
    "#test size means that the data will be splitted as 80% training 20% validation set\n",
    "#setting random state into a fixed number ensures the same result is obtained when the code is run again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train_2)\n",
    "x_valid = scaler.transform(x_valid_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 18237.99571917808\n",
      "R^2 score: 0.8830684784071265\n"
     ]
    }
   ],
   "source": [
    "#XGBoost - method 2\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "XGBRegressor().fit(x_train_2, y_train_2)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=300, #number of trees that the model builds, it should be not too high not too low\n",
    "    learning_rate=0.01, #step-size, used to prevent overfitting, it should be not too lare not too low\n",
    "    max_depth=5, #maximum depth of a tree\n",
    "    subsample=0.7, #fraction of samples used for training each tree\n",
    "    )\n",
    "model.fit(x_train_2, y_train_2)\n",
    "y_pred_2 = model.predict(x_valid_2)\n",
    "score = mean_absolute_error(y_valid_2, y_pred_2)\n",
    "score2 = r2_score(y_valid_2, y_pred_2)\n",
    "print(\"Mean Absolute Error:\", score)\n",
    "print(\"R^2 score:\", score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.6}\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators' : [50, 100, 200, 300],\n",
    "    'learning_rate' : [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth' : [5,7,9],\n",
    "    'subsample' : [0.4,0.6,0.8,1.0]\n",
    "}\n",
    "model = XGBRegressor()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=hyperparameter_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "#negative MAE is used because the algorithm is trying to minimize the error\n",
    "#cv stands for cross validation - which is a technique were data is split into smaller subsets and each of them is tried along the training. \n",
    "\n",
    "grid_search.fit(x_train_2, y_train_2)\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "print(best_params)\n",
    "print(best_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 15694.901353809932\n",
      "R^2 score: 0.9082550125223925\n"
     ]
    }
   ],
   "source": [
    "XGBRegressor().fit(x_train_2, y_train_2)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100, #number of trees that the model builds, it should be not too high not too low\n",
    "    learning_rate=0.1, #step-size, used to prevent overfitting, it should be not too lare not too low\n",
    "    max_depth=7, #maximum depth of a tree\n",
    "    subsample=0.6, #fraction of samples used for training each tree\n",
    "    )\n",
    "model.fit(x_train_2, y_train_2)\n",
    "y_pred_2 = model.predict(x_valid_2)\n",
    "score = mean_absolute_error(y_valid_2, y_pred_2)\n",
    "score2 = r2_score(y_valid_2, y_pred_2)\n",
    "print(\"Mean Absolute Error:\", score)\n",
    "print(\"R^2 score:\", score2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying out this set of steps, final result is close but lower than the first project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Project 2 was first tried without log transformation and results were noted. Later on it was tried with log transfromation and the results did not change significantly. Therefore it will not be apllied in further projects. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-housing-prices-Gh6gILXU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

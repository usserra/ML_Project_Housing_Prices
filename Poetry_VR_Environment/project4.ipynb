{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 4 is created to see whether a different approach in data cleaning works better in the end for the ML algorithm, XGBoost."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This project applies the method of a different participant from Kaggle. It was done to compare models created by myself with others. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: \n",
    "1. Download data set\n",
    "2. Make ID column the name of the rows\n",
    "3. Fill NaN values using different methods\n",
    "4. Apply One-Hot Encoding to deal with nominal data\n",
    "5. Calculate MI scores\n",
    "6. Create new features\n",
    "7. Split the data into training and validation sets\n",
    "8. Apply scaling\n",
    "9. Apply XGBoost algorithm\n",
    "10. Apply GridSearch algorithm to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_set = \"/Users/serraus/Desktop/house-prices-advanced-regression-techniques/train.csv\"\n",
    "train_set_data = pd.read_csv(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_data.set_index(\"Id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_sheet import category_calculator\n",
    "for column in train_set_data.columns:\n",
    "    print(\"Column:\", column)\n",
    "    category_calculator(train_set_data[column])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For some categorical features, NaN means that the feature does not exist in the house.\n",
    "# So we replace NaN with 'None'.\n",
    "none_cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', \n",
    "             'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "             'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "             'MasVnrType', 'MSSubClass']\n",
    "for col in none_cols:\n",
    "    train_set_data[col] = train_set_data[col].fillna('None')\n",
    "\n",
    "# For some numerical features, NaN means that the feature does not exist in the house.\n",
    "# So we replace NaN with 0.\n",
    "zero_cols = ['GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    "             'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath',\n",
    "             'MasVnrArea']\n",
    "for col in zero_cols:\n",
    "    train_set_data[col] = train_set_data[col].fillna(0)\n",
    "\n",
    "# For the rest of the categorical features, we replace NaN with the most common value (mode).\n",
    "mode_cols = ['MSZoning', 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'Functional', 'Utilities']\n",
    "for col in mode_cols:\n",
    "    train_set_data[col] = train_set_data[col].fillna(train_set_data[col].mode()[0])\n",
    "\n",
    "# For 'LotFrontage', we fill in missing values by the median LotFrontage of the neighborhood.\n",
    "train_set_data[\"LotFrontage\"] = train_set_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "train_set_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 306)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform one-hot encoding\n",
    "all_data = pd.get_dummies(train_set_data)\n",
    "\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AgeHouse  TotalSF  HasPool\n",
      "Id                              \n",
      "1            5     2566        0\n",
      "2           31     2524        0\n",
      "3            7     2706        0\n",
      "4           91     2473        0\n",
      "5            8     3343        0\n",
      "...        ...      ...      ...\n",
      "1456         8     2600        0\n",
      "1457        32     3615        0\n",
      "1458        69     3492        0\n",
      "1459        60     2156        0\n",
      "1460        43     2512        0\n",
      "\n",
      "[1460 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from function_sheet import new_features\n",
    "new_training_data_features = new_features(all_data)\n",
    "print(new_training_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1460 entries, 1 to 1460\n",
      "Columns: 306 entries, MSSubClass to SaleCondition_Partial\n",
      "dtypes: bool(266), float64(3), int64(37)\n",
      "memory usage: 846.9 KB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice      5.589165\n",
       "TotalSF        0.677195\n",
       "OverallQual    0.563705\n",
       "GrLivArea      0.481239\n",
       "YearBuilt      0.369837\n",
       "GarageArea     0.366009\n",
       "TotalBsmtSF    0.365900\n",
       "GarageCars     0.353618\n",
       "AgeHouse       0.345603\n",
       "1stFlrSF       0.307304\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from function_sheet import mi_scores\n",
    "x = all_data\n",
    "y = all_data[\"SalePrice\"]\n",
    "mi = mi_scores(x, y)\n",
    "mi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = all_data.drop(\"SalePrice\", axis = 1)\n",
    "y_4 = all_data.SalePrice\n",
    "print(X_4, y_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train/validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_4, y_4, test_size=0.2, random_state=42) \n",
    "#test size means that the data will be splitted as 80% training 20% validation set\n",
    "#setting random state into a fixed number ensures the same result is obtained when the code is run again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 18946.37569563356\n",
      "R^2 score: 0.8586945123441682\n"
     ]
    }
   ],
   "source": [
    "#XGBoost \n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "XGBRegressor().fit(x_train, y_train)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=300, #number of trees that the model builds, it should be not too high not too low\n",
    "    learning_rate=0.01, #step-size, used to prevent overfitting, it should be not too lare not too low\n",
    "    max_depth=5, #maximum depth of a tree\n",
    "    subsample=0.7, #fraction of samples used for training each tree\n",
    "    )\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "score = mean_absolute_error(y_valid, y_pred)\n",
    "score2 = r2_score(y_valid, y_pred)\n",
    "print(\"Mean Absolute Error:\", score)\n",
    "print(\"R^2 score:\", score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators' : [50, 100, 200, 300],\n",
    "    'learning_rate' : [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth' : [5,7,9],\n",
    "    'subsample' : [0.4,0.6,0.8,1.0]\n",
    "}\n",
    "model = XGBRegressor()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=hyperparameter_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "#negative MAE is used because the algorithm is trying to minimize the error\n",
    "#cv stands for cross validation - which is a technique were data is split into smaller subsets and each of them is tried along the training. \n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.6}\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "print(best_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 14960.440282534246\n",
      "R^2 score: 0.9073020073233422\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "XGBRegressor().fit(x_train, y_train)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=200, #number of trees that the model builds, it should be not too high not too low\n",
    "    learning_rate=0.1, #step-size, used to prevent overfitting, it should be not too lare not too low\n",
    "    max_depth=5, #maximum depth of a tree\n",
    "    subsample=0.6, #fraction of samples used for training each tree\n",
    "    )\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "score = mean_absolute_error(y_valid, y_pred)\n",
    "score2 = r2_score(y_valid, y_pred)\n",
    "print(\"Mean Absolute Error:\", score)\n",
    "print(\"R^2 score:\", score2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no significant difference of project 4 with other side projects. The initial project turned out to be the best result with approximately 0.93 R^2 score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-housing-prices-Gh6gILXU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

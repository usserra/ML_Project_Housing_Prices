{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 3 is created to see whether a different approach in data cleaning works better in the end for the ML algorithm, XGBoost."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: \n",
    "1. Download data set\n",
    "2. Make ID column the name of the rows\n",
    "3. Delete columns where NaN data is present in more than half of the rows\n",
    "4. Apply Ordinal Encoding to deal with categorical data\n",
    "5. Apply KNN imputation to deal with remaining rows where NaN data is still present\n",
    "6. Calculate MI scores\n",
    "7. Create new features\n",
    "8. Delete columns that make up the new features\n",
    "9. Delete columns with least MI scores\n",
    "10. Split the data into training and validation sets\n",
    "11. Apply scaling\n",
    "12. Apply XGBoost algorithm\n",
    "13. Apply GridSearch algorithm to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_set = \"/Users/serraus/Desktop/house-prices-advanced-regression-techniques/train.csv\"\n",
    "trainn_data = pd.read_csv(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainn_data.set_index(\"Id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
       "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n",
       "       'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainn_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainn_data.drop(['Alley', 'MasVnrType', 'Fence', 'PoolQC'], axis = 1, inplace= True)\n",
    "print(trainn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_sheet import category_calculator\n",
    "for column in trainn_data.columns:\n",
    "    print(\"Column:\", column)\n",
    "    category_calculator(trainn_data[column])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_sheet import ordinal_encoder\n",
    "encoded_trainn_data = ordinal_encoder(trainn_data)\n",
    "print(encoded_trainn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_sheet import imputer\n",
    "imputed_trainn_data = imputer(encoded_trainn_data)\n",
    "print(imputed_trainn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice       5.585131\n",
       "MiscFeature     0.760556\n",
       "FireplaceQu     0.576683\n",
       "OverallQual     0.576350\n",
       "Neighborhood    0.512732\n",
       "GrLivArea       0.483863\n",
       "YearBuilt       0.371146\n",
       "TotalBsmtSF     0.367192\n",
       "GarageCars      0.366340\n",
       "GarageArea      0.362888\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from function_sheet import mi_scores\n",
    "x = imputed_trainn_data\n",
    "y = imputed_trainn_data[\"SalePrice\"]\n",
    "mi = mi_scores(x, y)\n",
    "mi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AgeHouse  TotalSF  HasPool\n",
      "0          5.0   2566.0        0\n",
      "1         31.0   2524.0        0\n",
      "2          7.0   2706.0        0\n",
      "3         91.0   2473.0        0\n",
      "4          8.0   3343.0        0\n",
      "...        ...      ...      ...\n",
      "1455       8.0   2600.0        0\n",
      "1456      32.0   3615.0        0\n",
      "1457      69.0   3492.0        0\n",
      "1458      60.0   2156.0        0\n",
      "1459      43.0   2512.0        0\n",
      "\n",
      "[1460 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from function_sheet import new_features\n",
    "new_training_data_features = new_features(imputed_trainn_data)\n",
    "print(new_training_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_trainn_data.drop(['YrSold', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'TotalBsmtSF', 'PoolArea'], axis = 1, inplace = True)\n",
    "print(imputed_trainn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice       5.576915\n",
       "MiscFeature     0.757663\n",
       "TotalSF         0.677362\n",
       "FireplaceQu     0.574712\n",
       "OverallQual     0.561081\n",
       "Neighborhood    0.509944\n",
       "GrLivArea       0.484220\n",
       "GarageArea      0.363773\n",
       "GarageCars      0.362115\n",
       "BsmtQual        0.342121\n",
       "AgeHouse        0.336283\n",
       "KitchenQual     0.332813\n",
       "ExterQual       0.315364\n",
       "GarageYrBlt     0.298041\n",
       "MSSubClass      0.279888\n",
       "FullBath        0.261243\n",
       "GarageFinish    0.252476\n",
       "YearRemodAdd    0.250073\n",
       "GarageType      0.230289\n",
       "TotRmsAbvGrd    0.218583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mi = mi_scores(x, y)\n",
    "new_mi.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExterCond       0.009741\n",
       "ScreenPorch     0.009555\n",
       "RoofStyle       0.008706\n",
       "Heating         0.007959\n",
       "BsmtFinSF2      0.007757\n",
       "LowQualFinSF    0.006818\n",
       "BsmtFinType2    0.004662\n",
       "BsmtHalfBath    0.000000\n",
       "Condition2      0.000000\n",
       "Functional      0.000000\n",
       "3SsnPorch       0.000000\n",
       "RoofMatl        0.000000\n",
       "MiscVal         0.000000\n",
       "MoSold          0.000000\n",
       "Utilities       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mi.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed = [\n",
    "    'RoofStyle',\n",
    "    'BsmtHalfBath',\n",
    "    'RoofMatl',\n",
    "    'LowQualFinSF',\n",
    "    'BsmtFinSF2',\n",
    "    'Utilities',\n",
    "    '3SsnPorch',\n",
    "    'MoSold',\n",
    "    'Condition2', \n",
    "    'ExterCond', \n",
    "    'ScreenPorch',\n",
    "    'Heating',\n",
    "    'BsmtFinType2',\n",
    "    'Functional',\n",
    "    'MiscVal'\n",
    "\n",
    "]\n",
    "imputed_trainn_data.drop(columns=columns_to_be_removed, inplace=True) #inplace = True modifies the original DataFrame\n",
    "print(imputed_trainn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = imputed_trainn_data.drop(\"SalePrice\", axis = 1)\n",
    "y_3 = imputed_trainn_data.SalePrice\n",
    "print(X_3, y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train/validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_3, y_3, test_size=0.2, random_state=42) \n",
    "#test size means that the data will be splitted as 80% training 20% validation set\n",
    "#setting random state into a fixed number ensures the same result is obtained when the code is run again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.transform(x_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 16852.189332726884\n",
      "R^2 score: 0.8922707339079821\n"
     ]
    }
   ],
   "source": [
    "#XGBoost \n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "XGBRegressor().fit(x_train, y_train)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=300, #number of trees that the model builds, it should be not too high not too low\n",
    "    learning_rate=0.01, #step-size, used to prevent overfitting, it should be not too lare not too low\n",
    "    max_depth=5, #maximum depth of a tree\n",
    "    subsample=0.7, #fraction of samples used for training each tree\n",
    "    )\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "score = mean_absolute_error(y_valid, y_pred)\n",
    "score2 = r2_score(y_valid, y_pred)\n",
    "print(\"Mean Absolute Error:\", score)\n",
    "print(\"R^2 score:\", score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators' : [50, 100, 200, 300],\n",
    "    'learning_rate' : [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth' : [5,7,9],\n",
    "    'subsample' : [0.4,0.6,0.8,1.0]\n",
    "}\n",
    "model = XGBRegressor()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=hyperparameter_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "#negative MAE is used because the algorithm is trying to minimize the error\n",
    "#cv stands for cross validation - which is a technique were data is split into smaller subsets and each of them is tried along the training. \n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.6}\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "print(best_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 13715.915065817637\n",
      "R^2 score: 0.9191487867244753\n"
     ]
    }
   ],
   "source": [
    "XGBRegressor().fit(x_train, y_train)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=200, #number of trees that the model builds, it should be not too high not too low\n",
    "    learning_rate=0.1, #step-size, used to prevent overfitting, it should be not too lare not too low\n",
    "    max_depth=5, #maximum depth of a tree\n",
    "    subsample=0.6, #fraction of samples used for training each tree\n",
    "    )\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "score = mean_absolute_error(y_valid, y_pred)\n",
    "score2 = r2_score(y_valid, y_pred)\n",
    "print(\"Mean Absolute Error:\", score)\n",
    "print(\"R^2 score:\", score2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of project 3 was better than project 2 however still lower than the original project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-housing-prices-Gh6gILXU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
